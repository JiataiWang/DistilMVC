#General
seed: 10
workers: 8
device: '0'
dataset_dir: "./datasets"
dataset_name: BDGP
batch_size: 256
temperature_t: 0.5
temperature_s: 1.0
temperature_d: 0.1
learning_rate: 0.0001
weight_decay: 0.

#Model
model_kwargs:
  Encoder:
    arch: [512, 1024, 2048, 512]
    activation: False
    function: relu
    batchnorm: False
  Decoder:
    arch: [512, 2048, 1024, 512]
    activation: False
    function: relu
    batchnorm: False
  predictor_hidden_dim: 128


#Pretrain
mse_epochs: 200
infoNCE_epochs: 10
iic_factor: 0.0005

#Fine-tuning
self_distil: 50



